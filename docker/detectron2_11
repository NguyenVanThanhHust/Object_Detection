FROM quangbd/pytorch:1.6.0-python3.6-cuda11.0-cudnn8-ubuntu18.04

# Install some basic utilities
RUN apt-get update && apt-get install -y \
    curl \
    ca-certificates \
    sudo \
    git \
    bzip2 \
    libx11-6 \
 && rm -rf /var/lib/apt/lists/*

# See https://pytorch.org/ for other options if you use a different version of CUDA
RUN pip install tensorboard cmake   # cmake from apt-get is too old

RUN pip install 'git+https://github.com/facebookresearch/fvcore'

RUN pip install einops sklearn opencv-python scipy tqdm pillow matplotlib
# Set a fixed model cache directory.

RUN apt-get update && sudo apt-get install libgflags-dev libgoogle-glog-dev libopencv-dev --yes
RUN pip install mkl-include

# Install the correct version of protobuf:
RUN wget https://github.com/protocolbuffers/protobuf/releases/download/v3.11.4/protobuf-cpp-3.11.4.tar.gz && tar xf protobuf-cpp-3.11.4.tar.gz
RUN export CXXFLAGS=-D_GLIBCXX_USE_CXX11_ABI=$(python3 -c 'import torch; print(int(torch.compiled_with_cxx11_abi()))'); \
	cd protobuf-3.11.4 && \
	./configure --prefix=$HOME/.local && make && make install

# install detectron2

RUN git clone https://github.com/facebookresearch/detectron2 -b v0.4 detectron2
# set FORCE_CUDA because during `docker build` cuda is not accessible
ENV FORCE_CUDA="1"
# This will by default build detectron2 for all common cuda architectures and take a lot more time,
# because inside `docker build`, there is no way to tell which architecture will be used.
ARG TORCH_CUDA_ARCH_LIST="Kepler;Kepler+Tesla;Maxwell;Maxwell+Tegra;Pascal;Volta;Turing"
ENV TORCH_CUDA_ARCH_LIST="${TORCH_CUDA_ARCH_LIST}"

# Make RUN commands use the new environment:
# SHELL ["/bin/bash", "--login", "-c"]
RUN python3.6 -m pip install -e detectron2

WORKDIR /workspace/projects/
